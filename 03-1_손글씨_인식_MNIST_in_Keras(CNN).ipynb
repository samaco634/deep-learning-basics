{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samaco634/deep-learning-basics/blob/main/%5B%EB%94%A5%EB%9F%AC%EB%8B%9D%EA%B8%B0%EC%B4%88_03_1%5D%EC%86%90%EA%B8%80%EC%94%A8_%EC%9D%B8%EC%8B%9D_MNIST_in_Keras(CNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tkCb9hATzYw6"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2JROAkzYw9"
      },
      "source": [
        "# Introduction to Deep Learning with Keras and TensorFlow\n",
        "\n",
        "**Daniel Moser (UT Southwestern Medical Center)**\n",
        "\n",
        "**Resources: [Xavier Snelgrove](https://github.com/wxs/keras-mnist-tutorial), [Yash Katariya](https://github.com/yashk2810/MNIST-Keras)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZyMkU2vzYxB"
      },
      "source": [
        "딥 러닝의 기본 사항을 이해하는 데 도움이 되도록 이 데모에서는 정확도가 95%를 초과하는 손글씨 숫자를 분류하기 위한 CNN을 소개합니다. CNN은컨볼루션과 풀링의 개념을 도입한 심층 네트워크입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxRNCw8CzYxC"
      },
      "source": [
        "## AI를 위한 과제\n",
        "\n",
        "우리의 목표는 수천 개의 손으로 쓴 숫자 이미지에 인공 신경망을 구성하고 훈련시켜 제시될 때 다른 사람을 성공적으로 식별할 수 있도록 하는 것입니다. 통합될 데이터는 훈련용 이미지 60,000개와 테스트 이미지 10,000개가 포함된 MNIST 데이터베이스입니다. TensorFlow를 백엔드로 사용하는 Keras Python API를 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUamW7G2zYxD"
      },
      "source": [
        "<img src=\"https://github.com/AviatorMoser/keras-mnist-tutorial/blob/master/mnist.png?raw=1\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv-PWwGFzYxE"
      },
      "source": [
        "## 필수 Python 모듈\n",
        "\n",
        "먼저 일부 소프트웨어를 Python 환경에 로드해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwFcJpDuzYxF"
      },
      "outputs": [],
      "source": [
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random                        # for generating random numbers\n",
        "\n",
        "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n",
        "from keras.utils import np_utils                         # NumPy related tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpwNdSZWzYxF"
      },
      "source": [
        "## 훈련 데이터 불러오기\n",
        "\n",
        "MNIST 데이터셋은 Keras 내에 편리하게 번들로 제공되며 Python에서 일부 기능을 쉽게 분석할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVwCNKMGzYxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751c7d7f-11bb-49ba-a4b6-da1c961f17d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "X_train shape (60000, 28, 28)\n",
            "y_train shape (60000,)\n",
            "X_test shape (10000, 28, 28)\n",
            "y_test shape (10000,)\n"
          ]
        }
      ],
      "source": [
        "# The MNIST data is split between 60,000 28 x 28 pixel training images and 10,000 28 x 28 pixel images\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"X_train shape\", X_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"X_test shape\", X_test.shape)\n",
        "print(\"y_test shape\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRFTdFruzYxH"
      },
      "source": [
        "matplotlib를 사용하여 훈련 세트의 일부 샘플 이미지를 Jupyter Notebook에 직접 플롯할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZJ-QaWNzYxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "13892781-d785-42b4-b655-0a0ccf646855"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.rcParams['figure.figsize'] = (9,9) # Make the figures a bit bigger\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    num = random.randint(0, len(X_train))\n",
        "    plt.imshow(X_train[num], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Class {}\".format(y_train[num]))\n",
        "    \n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b2_3FLhzYxI"
      },
      "source": [
        "한 자릿수를 조금 더 자세히 살펴보고 마지막 자릿수를 나타내는 배열을 출력해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "손글씨 한 장의 이미지는 28 x 28 = 784개의 픽셀로 이루어져 있습니다.\n",
        "\n",
        "아래 코드로 픽셀 정보를 눈으로 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "erXgUSIuaHOQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnnDVXYYzYxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f8afa87-2bb2-4aa8-c847-b09f6242e597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0  149  254  254  254  254  254  164   41    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0   46  232  252  253  253  253  253  253  253  250   89    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0   46  166  253  253  253  253  253  253  253  253  253  246  149    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0  158  253  253  253  253  253  199  253  253  253  253  253  238   43  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0   43  242  253  253  253  132   53  211  253  253  185  170  253  253  153  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  112  253  253  253  179    6  120  253  253  253   78    5  116  162  149  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  112  253  253  253  168   27  219  253  253  236   52    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0   20  198  253  253  238  222  253  253  253   94    0    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0   75  246  253  253  253  253  253  206   15    0    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0  128  253  253  253  253  253  210   19    0    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0   48  237  253  253  253  253  253  180   18    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0   99  253  253  253  253  253  253  253  105    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0   19  193  253  253  239  220  253  253  253  207    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0  105  253  253  253  155   24  215  253  253  238   77    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0  105  253  253  242   39    0  112  253  253  253  214    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0  105  253  253  168    0    0   66  253  253  253  214    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0  105  253  253  175   20   20  147  253  253  253  204    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0  105  253  253  253  253  253  253  253  253  227   37    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0  105  253  253  253  253  253  253  253  248  135    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0   51  173  253  253  253  253  253  223   35    0    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  0  0  0  0  0  \n"
          ]
        }
      ],
      "source": [
        "# just a little function for pretty printing a matrix\n",
        "def matprint(mat, fmt=\"g\"):\n",
        "    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n",
        "    for x in mat:\n",
        "        for i, y in enumerate(x):\n",
        "            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n",
        "        print(\"\")\n",
        "\n",
        "# now print!        \n",
        "matprint(X_train[num])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLF16RkWzYxK"
      },
      "source": [
        "각 픽셀은 0-255 사이의 8비트 정수입니다. 0은 완전한 검정이고 255는 완전한 흰색입니다. 이것을 단일 채널 픽셀이라고 합니다. 모노크롬이라고 합니다.\n",
        "\n",
        "*재미있는 사실! 컴퓨터 화면에는 각 픽셀에 대해 빨강, 녹색, 파랑의 세 가지 채널이 있습니다. 이러한 각 채널은 또한 8비트 정수를 사용합니다. 3개 채널 -- 총 24비트 -- 16,777,216가지 색상 가능!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTtfUC_hzYxT"
      },
      "source": [
        "# Introducing Convolution! What is it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh66UoBdzYxU"
      },
      "source": [
        "이전에는 각 값의 정규화된 픽셀 값을 받아들이고 해당 값에 대해서만 작동하는 네트워크를 구축했습니다. 대신 각 이미지의 다른 특징(예: **곡률, 가장자리**)을 네트워크에 제공하고 네트워크에서 이미지 분류에 중요한 특징을 학습하도록 할 수 있다면 어떨까요?\n",
        "\n",
        "이것은 회선을 통해 가능합니다! 컨볼루션은 각 이미지를 통과하고 **기능 맵**을 생성하는 **커널**(필터)을 적용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtuNvMo9zYxU"
      },
      "source": [
        "<img src = 'convolution.gif' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVAS7On2zYxU"
      },
      "source": [
        "위의 예에서 이미지는 5 x 5 행렬이고 그 위에 있는 커널은 3 x 3 행렬입니다. 이미지와 커널 사이에 내적 연산이 발생하고 컨볼루션 피쳐가 생성됩니다. CNN의 각 커널은 이미지의 다른 특성을 학습합니다.\n",
        "\n",
        "커널은 사진 편집 소프트웨어에서 흐림, 가장자리 감지, 선명하게 하기 등을 적용하는 데 자주 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah3STfYqzYxU"
      },
      "source": [
        "<img src = 'kernels.png' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5gW8bxJzYxU"
      },
      "source": [
        "딥 러닝 네트워크의 커널은 유사한 방식으로 사용됩니다. 즉, 일부 기능을 강조 표시합니다. **max pooling**이라는 시스템과 결합하여 강조 표시되지 않은 요소는 각 기능 맵에서 삭제되어 관심 있는 기능만 남겨두고 학습된 매개변수의 수를 줄이고 계산 비용(예: 시스템 메모리)을 줄입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0UFzdQOzYxU"
      },
      "source": [
        "<img src = 'max_pooling.png' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBVH5T5MzYxU"
      },
      "source": [
        "우리는 또한 컨볼루션의 컨볼루션을 사용할 수 있습니다. 커널에 맞는 충분한 픽셀이 있는 한 원하는 만큼 컨볼루션을 쌓을 수 있습니다.\n",
        "\n",
        "*경고: deep convolutions 에서 찾을 수 있는 내용은 인식할 수 없는 것처럼 보일 수 있습니다.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDOGm6I_zYxU"
      },
      "source": [
        "<img src = 'go_deeper.jpg' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcdXO38-zYxV"
      },
      "source": [
        "## Building a \"Deep\" Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0IhF51OizYxV"
      },
      "outputs": [],
      "source": [
        "# import some additional tools\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nQus4NJvzYxV"
      },
      "outputs": [],
      "source": [
        "# Reload the MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYYgsmMazYxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e2005e-19ea-40fb-8419-5529b8513aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training matrix shape (60000, 28, 28, 1)\n",
            "Testing matrix shape (10000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "# Again, do some formatting\n",
        "# Except we do not flatten each image into a 784-length vector because we want to perform convolutions first\n",
        "\n",
        "X_train = X_train.reshape(60000, 28, 28, 1) #add an additional dimension to represent the single-channel\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
        "X_test /= 255\n",
        "\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eBPJRG8XzYxV"
      },
      "outputs": [],
      "source": [
        "# one-hot format classes\n",
        "\n",
        "nb_classes = 10 # number of unique digits\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "18Ivhi2tzYxW"
      },
      "outputs": [],
      "source": [
        "model = Sequential()                                 # Linear stacking of layers\n",
        "\n",
        "# Convolution Layer 1\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\n",
        "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "convLayer01 = Activation('relu')                     # activation\n",
        "model.add(convLayer01)\n",
        "\n",
        "# Convolution Layer 2\n",
        "model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n",
        "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "model.add(Activation('relu'))                        # activation\n",
        "convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "model.add(convLayer02)\n",
        "\n",
        "# Convolution Layer 3\n",
        "model.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\n",
        "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "convLayer03 = Activation('relu')                     # activation\n",
        "model.add(convLayer03)\n",
        "\n",
        "# Convolution Layer 4\n",
        "model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
        "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "model.add(Activation('relu'))                        # activation\n",
        "convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "model.add(convLayer04)\n",
        "model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
        "\n",
        "# Fully Connected Layer 5\n",
        "model.add(Dense(512))                                # 512 FCN nodes\n",
        "model.add(BatchNormalization())                      # normalization\n",
        "model.add(Activation('relu'))                        # activation\n",
        "\n",
        "# Fully Connected Layer 6                       \n",
        "model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n",
        "model.add(Dense(10))                                 # final 10 FCN nodes\n",
        "model.add(Activation('softmax'))                     # softmax activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jhoqKDMzYxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76416d10-54db-4c42-cdb5-fc991157dca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 26, 26, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 24, 24, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 10, 10, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 10, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 10, 10, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8, 8, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 597,738\n",
            "Trainable params: 596,330\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WD0Pb07szYxW"
      },
      "outputs": [],
      "source": [
        "# we'll use the same optimizer\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI-9PZh2zYxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a75f028a-542f-4cc4-963a-e7932544344c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "468/468 [==============================] - 17s 11ms/step - loss: 0.0838 - accuracy: 0.9749 - val_loss: 0.1176 - val_accuracy: 0.9649\n",
            "Epoch 2/3\n",
            "468/468 [==============================] - 5s 10ms/step - loss: 0.0294 - accuracy: 0.9913 - val_loss: 0.0383 - val_accuracy: 0.9868\n",
            "Epoch 3/3\n",
            "457/468 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9930"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1404 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r468/468 [==============================] - 5s 11ms/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 0.0223 - val_accuracy: 0.9925\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97fce95b50>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.fit(X_train,Y_train, steps_per_epoch=60000//128, epochs=3, verbose=1, \n",
        "                    validation_data=(X_test, Y_test), validation_steps=10000//128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj-kFJvbzYxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c1e6ac-8f9f-44ce-9fc2-43fd6c4ea7a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9925\n",
            "Test score: 0.0223393477499485\n",
            "Test accuracy: 0.9925000071525574\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def prediction(image, model):\n",
        "    img = cv2.resize(image, (28, 28))\n",
        "    img = img / 255\n",
        "    img = img.reshape(1, 28, 28, 1)\n",
        "    predict = model.predict(img)\n",
        "    prob = np.amax(predict)\n",
        "    class_index = model.predict_classes(img)\n",
        "    result = class_index[0]\n",
        "    if prob < 0.75:\n",
        "        result = 0\n",
        "        prob = 0\n",
        "    return result, prob\n",
        "    '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "xXULFGd6Liph",
        "outputId": "e8b71949-f865-4d5d-c4d9-e336df464017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef prediction(image, model):\\n    img = cv2.resize(image, (28, 28))\\n    img = img / 255\\n    img = img.reshape(1, 28, 28, 1)\\n    predict = model.predict(img)\\n    prob = np.amax(predict)\\n    class_index = model.predict_classes(img)\\n    result = class_index[0]\\n    if prob < 0.75:\\n        result = 0\\n        prob = 0\\n    return result, prob\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ],
      "metadata": {
        "id": "TlcT7sYgL6_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "metadata": {
        "id": "beYvM02ML-2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "84fvIrfUMOpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_numbers(y_pred):\n",
        "    for number, per in enumerate(y_pred[0]):\n",
        "        if per != 0:\n",
        "            final_number = str(int(number))\n",
        "            per = round((per * 100), 2)\n",
        "            return final_number, per"
      ],
      "metadata": {
        "id": "qmPJCr1oTW-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"mnist.h5\")"
      ],
      "metadata": {
        "id": "8jZ3a-8LR6Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    frame = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # predict digit on video frame\n",
        "    img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    ret,img_binary = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
        "\n",
        "    kernel = cv2.getStructuringElement( cv2.MORPH_RECT, ( 5, 5 ) )\n",
        "    img_binary = cv2.morphologyEx(img_binary, cv2. MORPH_CLOSE, kernel)\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(img_binary, cv2.RETR_EXTERNAL, \n",
        "                            cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    try:\n",
        "        for contour in contours:\n",
        "\n",
        "            (x, y), radius = cv2.minEnclosingCircle(contour)\n",
        "            \n",
        "            if radius > 10: #noise버리기\n",
        "                xs, xe = int(x-radius), int(x+radius)\n",
        "                ys, ye = int(y-radius), int(y+radius)\n",
        "\n",
        "                img_digit = img_binary[ys:ye, xs:xe]\n",
        "\n",
        "                kernel = np.ones((5, 5), np.uint8)\n",
        "                img_digit = cv2.morphologyEx(img_digit, cv2.MORPH_DILATE, kernel)\n",
        "\n",
        "                #model = load_model('mnist.h5')\n",
        "\n",
        "                img_digit = cv2.resize(img_digit, (28, 28), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "                img_digit = img_digit / 255.0\n",
        "\n",
        "                img_input = img_digit.reshape(1, 28, 28, 1)\n",
        "                predictions = model.predict(img_input, verbose=0)\n",
        "\n",
        "\n",
        "                number = np.argmax(predictions)\n",
        "                #print(number)\n",
        "\n",
        "                bbox_array= cv2.rectangle(bbox_array, (xs, ys), (xe, ye), (255, 255, 0), 2)\n",
        "\n",
        "\n",
        "                location = (x, y - 10)\n",
        "                font = cv2.FONT_HERSHEY_COMPLEX  \n",
        "                fontScale = 1.2\n",
        "                bbox_array = cv2.putText(bbox_array, str(number), (xs, ys), font, fontScale, (0,255,0), 2)\n",
        "\n",
        "    except Exception as e:\n",
        "            pass\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Howj-VDkMQx7",
        "outputId": "2dda86a3-e627-42fd-fe36-353466dd40ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Tensorflow (GPU)",
      "language": "python",
      "name": "py3.6-tfgpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
