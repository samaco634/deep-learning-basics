{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samaco634/deep-learning-basics/blob/main/%5B%EB%94%A5%EB%9F%AC%EB%8B%9D%EA%B8%B0%EC%B4%88_03%5D%EC%86%90%EA%B8%80%EC%94%A8_%EC%9D%B8%EC%8B%9D_MNIST_in_Keras(CNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tkCb9hATzYw6"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2JROAkzYw9"
      },
      "source": [
        "# Introduction to Deep Learning with Keras and TensorFlow\n",
        "\n",
        "**Daniel Moser (UT Southwestern Medical Center)**\n",
        "\n",
        "**Resources: [Xavier Snelgrove](https://github.com/wxs/keras-mnist-tutorial), [Yash Katariya](https://github.com/yashk2810/MNIST-Keras)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZyMkU2vzYxB"
      },
      "source": [
        "딥 러닝의 기본 사항을 이해하는 데 도움이 되도록 이 데모에서는 정확도가 95%를 초과하는 손글씨 숫자를 분류하기 위한 CNN을 소개합니다. CNN은컨볼루션과 풀링의 개념을 도입한 심층 네트워크입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxRNCw8CzYxC"
      },
      "source": [
        "## AI를 위한 과제\n",
        "\n",
        "우리의 목표는 수천 개의 손으로 쓴 숫자 이미지에 인공 신경망을 구성하고 훈련시켜 제시될 때 다른 사람을 성공적으로 식별할 수 있도록 하는 것입니다. 통합될 데이터는 훈련용 이미지 60,000개와 테스트 이미지 10,000개가 포함된 MNIST 데이터베이스입니다. TensorFlow를 백엔드로 사용하는 Keras Python API를 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUamW7G2zYxD"
      },
      "source": [
        "<img src=\"https://github.com/AviatorMoser/keras-mnist-tutorial/blob/master/mnist.png?raw=1\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv-PWwGFzYxE"
      },
      "source": [
        "## 필수 Python 모듈\n",
        "\n",
        "먼저 일부 소프트웨어를 Python 환경에 로드해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwFcJpDuzYxF"
      },
      "outputs": [],
      "source": [
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random                        # for generating random numbers\n",
        "\n",
        "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n",
        "from keras.utils import np_utils                         # NumPy related tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpwNdSZWzYxF"
      },
      "source": [
        "## 훈련 데이터 불러오기\n",
        "\n",
        "MNIST 데이터셋은 Keras 내에 편리하게 번들로 제공되며 Python에서 일부 기능을 쉽게 분석할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVwCNKMGzYxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e109c1bf-00ee-4403-aa78-e4208ab238df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "X_train shape (60000, 28, 28)\n",
            "y_train shape (60000,)\n",
            "X_test shape (10000, 28, 28)\n",
            "y_test shape (10000,)\n"
          ]
        }
      ],
      "source": [
        "# The MNIST data is split between 60,000 28 x 28 pixel training images and 10,000 28 x 28 pixel images\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"X_train shape\", X_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"X_test shape\", X_test.shape)\n",
        "print(\"y_test shape\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRFTdFruzYxH"
      },
      "source": [
        "matplotlib를 사용하여 훈련 세트의 일부 샘플 이미지를 Jupyter Notebook에 직접 플롯할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZJ-QaWNzYxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "58a540e2-2f88-482d-c609-89e179d9224a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.rcParams['figure.figsize'] = (9,9) # Make the figures a bit bigger\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    num = random.randint(0, len(X_train))\n",
        "    plt.imshow(X_train[num], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Class {}\".format(y_train[num]))\n",
        "    \n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b2_3FLhzYxI"
      },
      "source": [
        "한 자릿수를 조금 더 자세히 살펴보고 마지막 자릿수를 나타내는 배열을 출력해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "손글씨 한 장의 이미지는 28 x 28 = 784개의 픽셀로 이루어져 있습니다.\n",
        "\n",
        "아래 코드로 픽셀 정보를 눈으로 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "erXgUSIuaHOQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnnDVXYYzYxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404cb342-2c0f-4377-8d9c-5e7ea31964d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0   46  175  254  224  101   11    0    0   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0   72  233  253  253  236  253  198   50    0   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0   46  233  253  149   23   11  133  252  233   46   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0  162  253  228   14    0    0    0   87  243  196   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0   45  245  253   98    0    0    0    0    0   85  253  45  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0   84  255  247   35    0    0    0    0    0   28  237  67  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  149  254  176    0    0    0    0    0    4  151  174   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  149  254  119    0    0    0    0    0  129  253  223   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  149  254  186    3    0    0    0   29  189  253  240   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0  128  254  253   15    0   23  158  231  253  253  178   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0   67  255  254  205  214  254  255  254  254  254  170   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0  135  253  253  253  253  163  128  253  253  104   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    2   54  133   89   23    0   60  253  253  104   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0   74  253  253  104   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0  134  253  253   60   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0  135  254  254   30   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0  196  253  229   14   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0   20  238  253  208    0   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0   30  253  253  208    9   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    4  148  253  133    0   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0   0  0  0  0  0  0  0  0  0  \n",
            "0  0  0  0  0  0  0  0    0    0    0    0    0    0    0    0    0    0    0   0  0  0  0  0  0  0  0  0  \n"
          ]
        }
      ],
      "source": [
        "# just a little function for pretty printing a matrix\n",
        "def matprint(mat, fmt=\"g\"):\n",
        "    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n",
        "    for x in mat:\n",
        "        for i, y in enumerate(x):\n",
        "            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n",
        "        print(\"\")\n",
        "\n",
        "# now print!        \n",
        "matprint(X_train[num])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLF16RkWzYxK"
      },
      "source": [
        "각 픽셀은 0-255 사이의 8비트 정수입니다. 0은 완전한 검정이고 255는 완전한 흰색입니다. 이것을 단일 채널 픽셀이라고 합니다. 모노크롬이라고 합니다.\n",
        "\n",
        "*재미있는 사실! 컴퓨터 화면에는 각 픽셀에 대해 빨강, 녹색, 파랑의 세 가지 채널이 있습니다. 이러한 각 채널은 또한 8비트 정수를 사용합니다. 3개 채널 -- 총 24비트 -- 16,777,216가지 색상 가능!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTtfUC_hzYxT"
      },
      "source": [
        "# Introducing Convolution! What is it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh66UoBdzYxU"
      },
      "source": [
        "이전에는 각 값의 정규화된 픽셀 값을 받아들이고 해당 값에 대해서만 작동하는 네트워크를 구축했습니다. 대신 각 이미지의 다른 특징(예: **곡률, 가장자리**)을 네트워크에 제공하고 네트워크에서 이미지 분류에 중요한 특징을 학습하도록 할 수 있다면 어떨까요?\n",
        "\n",
        "이것은 회선을 통해 가능합니다! 컨볼루션은 각 이미지를 통과하고 **기능 맵**을 생성하는 **커널**(필터)을 적용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtuNvMo9zYxU"
      },
      "source": [
        "<img src = 'convolution.gif' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVAS7On2zYxU"
      },
      "source": [
        "위의 예에서 이미지는 5 x 5 행렬이고 그 위에 있는 커널은 3 x 3 행렬입니다. 이미지와 커널 사이에 내적 연산이 발생하고 컨볼루션 피쳐가 생성됩니다. CNN의 각 커널은 이미지의 다른 특성을 학습합니다.\n",
        "\n",
        "커널은 사진 편집 소프트웨어에서 흐림, 가장자리 감지, 선명하게 하기 등을 적용하는 데 자주 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah3STfYqzYxU"
      },
      "source": [
        "<img src = 'kernels.png' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5gW8bxJzYxU"
      },
      "source": [
        "딥 러닝 네트워크의 커널은 유사한 방식으로 사용됩니다. 즉, 일부 기능을 강조 표시합니다. **max pooling**이라는 시스템과 결합하여 강조 표시되지 않은 요소는 각 기능 맵에서 삭제되어 관심 있는 기능만 남겨두고 학습된 매개변수의 수를 줄이고 계산 비용(예: 시스템 메모리)을 줄입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0UFzdQOzYxU"
      },
      "source": [
        "<img src = 'max_pooling.png' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBVH5T5MzYxU"
      },
      "source": [
        "우리는 또한 컨볼루션의 컨볼루션을 사용할 수 있습니다. 커널에 맞는 충분한 픽셀이 있는 한 원하는 만큼 컨볼루션을 쌓을 수 있습니다.\n",
        "\n",
        "*경고: deep convolutions 에서 찾을 수 있는 내용은 인식할 수 없는 것처럼 보일 수 있습니다.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDOGm6I_zYxU"
      },
      "source": [
        "<img src = 'go_deeper.jpg' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcdXO38-zYxV"
      },
      "source": [
        "## Building a \"Deep\" Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0IhF51OizYxV"
      },
      "outputs": [],
      "source": [
        "# import some additional tools\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nQus4NJvzYxV"
      },
      "outputs": [],
      "source": [
        "# Reload the MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYYgsmMazYxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8887119-c7c1-46ec-cce9-be491d4af64d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training matrix shape (60000, 28, 28, 1)\n",
            "Testing matrix shape (10000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "# Again, do some formatting\n",
        "# Except we do not flatten each image into a 784-length vector because we want to perform convolutions first\n",
        "\n",
        "X_train = X_train.reshape(60000, 28, 28, 1) #add an additional dimension to represent the single-channel\n",
        "X_test = X_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
        "X_test /= 255\n",
        "\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eBPJRG8XzYxV"
      },
      "outputs": [],
      "source": [
        "# one-hot format classes\n",
        "\n",
        "nb_classes = 10 # number of unique digits\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "18Ivhi2tzYxW"
      },
      "outputs": [],
      "source": [
        "model = Sequential()                                 # Linear stacking of layers\n",
        "\n",
        "# Convolution Layer 1\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\n",
        "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "convLayer01 = Activation('relu')                     # activation\n",
        "model.add(convLayer01)\n",
        "\n",
        "# Convolution Layer 2\n",
        "model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n",
        "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "model.add(Activation('relu'))                        # activation\n",
        "convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "model.add(convLayer02)\n",
        "\n",
        "# Convolution Layer 3\n",
        "model.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\n",
        "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "convLayer03 = Activation('relu')                     # activation\n",
        "model.add(convLayer03)\n",
        "\n",
        "# Convolution Layer 4\n",
        "model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
        "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
        "model.add(Activation('relu'))                        # activation\n",
        "convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
        "model.add(convLayer04)\n",
        "model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
        "\n",
        "# Fully Connected Layer 5\n",
        "model.add(Dense(512))                                # 512 FCN nodes\n",
        "model.add(BatchNormalization())                      # normalization\n",
        "model.add(Activation('relu'))                        # activation\n",
        "\n",
        "# Fully Connected Layer 6                       \n",
        "model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n",
        "model.add(Dense(10))                                 # final 10 FCN nodes\n",
        "model.add(Activation('softmax'))                     # softmax activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jhoqKDMzYxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da1bb478-9681-4d81-8477-6745c582ae8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 26, 26, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 24, 24, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 10, 10, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 10, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 10, 10, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8, 8, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 597,738\n",
            "Trainable params: 596,330\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WD0Pb07szYxW"
      },
      "outputs": [],
      "source": [
        "# we'll use the same optimizer\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI-9PZh2zYxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7ea2fe-1f3a-4a21-a0af-89ce1aa63a6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 21s 6ms/step - loss: 0.0835 - accuracy: 0.9738 - val_loss: 0.0354 - val_accuracy: 0.9885\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0420 - accuracy: 0.9868 - val_loss: 0.0375 - val_accuracy: 0.9877\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0333 - accuracy: 0.9898 - val_loss: 0.0226 - val_accuracy: 0.9929\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 0.0252 - val_accuracy: 0.9925\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.0240 - val_accuracy: 0.9925\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3d601ef450>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.fit(X_train,Y_train, epochs=5, verbose=1, \n",
        "                    validation_data=(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj-kFJvbzYxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a798291-0d55-41bf-8d34-95e4fc810b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0240 - accuracy: 0.9925\n",
            "Test score: 0.024007363244891167\n",
            "Test accuracy: 0.9925000071525574\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def prediction(image, model):\n",
        "    img = cv2.resize(image, (28, 28))\n",
        "    img = img / 255\n",
        "    img = img.reshape(1, 28, 28, 1)\n",
        "    predict = model.predict(img)\n",
        "    prob = np.amax(predict)\n",
        "    class_index = model.predict_classes(img)\n",
        "    result = class_index[0]\n",
        "    if prob < 0.75:\n",
        "        result = 0\n",
        "        prob = 0\n",
        "    return result, prob\n",
        "    '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "xXULFGd6Liph",
        "outputId": "708adf7c-f5f7-449a-eec2-23a6e7e06cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef prediction(image, model):\\n    img = cv2.resize(image, (28, 28))\\n    img = img / 255\\n    img = img.reshape(1, 28, 28, 1)\\n    predict = model.predict(img)\\n    prob = np.amax(predict)\\n    class_index = model.predict_classes(img)\\n    result = class_index[0]\\n    if prob < 0.75:\\n        result = 0\\n        prob = 0\\n    return result, prob\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ],
      "metadata": {
        "id": "TlcT7sYgL6_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "metadata": {
        "id": "beYvM02ML-2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "84fvIrfUMOpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_numbers(y_pred):\n",
        "    for number, per in enumerate(y_pred[0]):\n",
        "        if per != 0:\n",
        "            final_number = str(int(number))\n",
        "            per = round((per * 100), 2)\n",
        "            return final_number, per"
      ],
      "metadata": {
        "id": "qmPJCr1oTW-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    frame = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # predict digit on video frame\n",
        "    img_gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "    ret, thresh = cv2.threshold(img_gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    contours, hierachy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    #cv2.drawContours(bbox_array, contours, -1, (0, 255, 0), 3)\n",
        "\n",
        "    try:\n",
        "        for contour in contours:\n",
        "            (x, y), radius = cv2.minEnclosingCircle(contour)\n",
        "            if radius > 10: #noise버리기\n",
        "                xs, xe = int(x-radius), int(x+radius)\n",
        "                ys, ye = int(y-radius), int(y+radius)\n",
        "\n",
        "                bbox_array = cv2.rectangle(bbox_array, (xs, ys), (xe, ye), (255, 255, 0), 2)\n",
        "                roi = thresh[ys:ye, xs:xe]\n",
        "                dst = cv2.resize(roi, dsize =(40, 40), interpolation=cv2.INTER_AREA)\n",
        "                dst = cv2.resize(dst, dsize =(20, 20), interpolation=cv2.INTER_AREA)\n",
        "                \n",
        "#                        print(dst)\n",
        "                A = np.zeros((28, 28))\n",
        "                A[4:-4, 4:-4] = dst[:,:]\n",
        "                A = A/255\n",
        "                A = A.reshape(-1, 28, 28, 1)\n",
        "                num = np.argmax(model.predict(A, verbose=0))\n",
        "                bbox_array = cv2.putText(bbox_array, str(num), (xs, ys),  cv2.FONT_HERSHEY_PLAIN, 2, (255,0,0))\n",
        "#                        print(roi.shape)\n",
        "\n",
        "                \n",
        "    except Exception as e:\n",
        "        pass\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Howj-VDkMQx7",
        "outputId": "7bd684dd-7884-405a-8741-261ccb66c797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"mnist.h5\")"
      ],
      "metadata": {
        "id": "8jZ3a-8LR6Cb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Tensorflow (GPU)",
      "language": "python",
      "name": "py3.6-tfgpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
