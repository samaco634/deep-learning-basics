{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdmgP2QGjYxlEcaULxGzsy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samaco634/deep-learning-basics/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_02_1__%EA%BD%83_%EC%9D%B4%EB%AF%B8%EC%A7%80_%EB%B6%84%EB%A5%98_%EA%B5%AC%EA%B8%80%EC%9D%B4%EB%AF%B8%EC%A7%80_%EB%8B%A4%EC%9A%B4%EB%A1%9C%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 튜토리얼은 꽃 이미지를 분류하는 방법을 보여줍니다. `tf.keras.Sequential` 모델을 사용하여 이미지 분류자를 생성하고 `tf.keras.utils.image_dataset_from_directory`를 사용하여 데이터를 로드합니다. 다음 개념에 대한 실질적인 경험을 얻을 수 있을 겁니다.\n",
        "\n",
        "- 디스크에서 데이터세트를 효율적으로 로드합니다.\n",
        "- 데이터 증강 및 드롭아웃을 포함하여 과대적합을 식별하고 이를 완화하는 기술을 적용합니다.\n",
        "\n",
        "이 튜토리얼은 기본적인 머신러닝 워크플로를 따릅니다.\n",
        "\n",
        "1. 학습 데이터 모으기\n",
        "2. 입력 파이프라인 빌드하기\n",
        "3. 모델 빌드하기\n",
        "4. 모델 훈련하기\n",
        "5. 모델 테스트하기\n",
        "6. 모델을 개선하고 프로세스 반복하기"
      ],
      "metadata": {
        "id": "ftBXtx3A5WEZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlow 및 기타 라이브러리 가져오기"
      ],
      "metadata": {
        "id": "XcC-D_ja5lcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "PdmzDzvb5mGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 데이터 모으기"
      ],
      "metadata": {
        "id": "WMdaLogB5M1p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_MxGg7P5Is8"
      },
      "outputs": [],
      "source": [
        "# 이미지를 구글에서 검색하여 다운로드하기 위한 util 설치\n",
        "!pip install -q jmd_imagescraper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "root = Path().cwd()/\"images\"\n",
        "\n",
        "from jmd_imagescraper.core import * # dont't worry, it's designed to work with import *\n",
        "\n",
        "#                       폴더 이름 / 검색어 / 이미지개수\n",
        "duckduckgo_search(root, \"rose\", \"장미\", max_results=500)\n",
        "duckduckgo_search(root, \"sunflower\", \"해바라기\", max_results=500)\n",
        "duckduckgo_search(root, \"tulip\", \"튤립\", max_results=500)"
      ],
      "metadata": {
        "id": "2ZkvCPFm545p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다운로드 후, 데이터세트 사본을 사용할 수 있습니다. 총 이미지의 개수를 알아 봅시다."
      ],
      "metadata": {
        "id": "7poYjw3S-C5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(list(root.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "metadata": {
        "id": "7TlTQCkj9_oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "장미의 경우는 다음과 같습니다."
      ],
      "metadata": {
        "id": "n8B16JcP-bnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "roses = list(root.glob('rose/*'))\n",
        "PIL.Image.open(str(roses[0]))"
      ],
      "metadata": {
        "id": "l3E-tC5Q-cLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PIL.Image.open(str(roses[1]))"
      ],
      "metadata": {
        "id": "qdKD0_pO-nsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "튤립 그림도 확인해봅시다."
      ],
      "metadata": {
        "id": "iIeEU2_9-rgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tulips = list(root.glob('tulip/*'))\n",
        "PIL.Image.open(str(tulips[0]))"
      ],
      "metadata": {
        "id": "Icvg87rW-vBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PIL.Image.open(str(tulips[1]))"
      ],
      "metadata": {
        "id": "7dmjQs3V-1LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras 유틸리티를 사용하여 데이터 로드하기\n",
        "\n",
        "유용한 `tf.keras.utils.image_dataset_from_directory` 유틸리티를 사용하여 디스크에서 이러한 이미지를 로드해 보겠습니다. 이러면 몇 줄의 코드로 디스크의 이미지 디렉터리에서 `tf.data.Dataset`로 이동하게 됩니다. "
      ],
      "metadata": {
        "id": "FiwjzBqj-9qn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터세트 만들기"
      ],
      "metadata": {
        "id": "WTgpNRit_RYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "로더에 대한 몇 가지 매개변수를 정의합니다."
      ],
      "metadata": {
        "id": "XDX0e1K__Tpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "U65kOkyy-9Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 개발할 때 검증 분할을 사용하는 것이 좋습니다. 이미지의 80%를 훈련에 사용하고 20%를 유효성 검사에 사용합니다."
      ],
      "metadata": {
        "id": "QV_FzQt1_bA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  root,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "Us9J5Sr2_aja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  root,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "aThrFnMK_rLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이러한 데이터세트의 class_names 속성에서 클래스 이름을 찾을 수 있습니다."
      ],
      "metadata": {
        "id": "wTbCaspz_0he"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "6OW7EZuh_yyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "1w_BBSB3_1ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이러한 데이터세트를 사용하는 모델을 model.fit(이 튜토리얼의 뒷부분에 표시)에 전달하여 모델을 훈련할 수 있습니다. "
      ],
      "metadata": {
        "id": "mxovFh-KALEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "LjY0DYsyAO4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "image_batch는 (32, 180, 180, 3) 형상의 텐서이며, 180x180x3 형상의 32개 이미지 묶음으로 되어 있습니다(마지막 차원은 색상 채널 RGB를 나타냄). label_batch는 형상 (32,)의 텐서이며 32개 이미지에 해당하는 레이블입니다.\n",
        "\n",
        "참고: 이들 텐서 중 하나에서 .numpy()를 호출하여 numpy.ndarray로 변환할 수 있습니다."
      ],
      "metadata": {
        "id": "fUs6fY_JAS2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 표준화하기\n",
        "RGB 채널 값은 [0, 255] 범위에 있습니다. 이것은 신경망에 이상적이지 않습니다. 일반적으로 입력 값을 작게 만들어야 합니다. 여기서는 tf.keras.layers.experimental.preprocessing.Rescaling 레이어를 사용하여 [0, 1] 범위에 있도록 값을 표준화합니다."
      ],
      "metadata": {
        "id": "73ShbmqsAZze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "ZU28ve-nAgng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 레이어를 사용하는 방법에는 두 가지가 있습니다. map을 호출하여 데이터세트에 레이어를 적용할 수 있습니다."
      ],
      "metadata": {
        "id": "976rGUjAAm28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixels values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "id": "D8SqnJEdAn5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "또는 모델 정의 내에 레이어를 포함하여 배포를 단순화할 수 있습니다. 여기서는 두 번째 접근법을 사용할 것입니다.\n",
        "\n",
        "참고: 픽셀 값을 [-1,1]으로 조정하려면 대신 Rescaling(1./127.5, offset=-1)를 작성할 수 있습니다.\n",
        "\n",
        "참고: 이전에 tf.keras.preprocessing.image_dataset_from_directory의 image_size 인수를 사용하여 이미지 크기를 조정했습니다. 모델에 크기 조정 논리를 포함하려면 tf.keras.layers.experimental.preprocessing.Resizing 레이어를 대신 사용할 수 있습니다."
      ],
      "metadata": {
        "id": "BY0fkDhlA1jg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 성능을 위한 데이터세트 구성하기\n",
        "버퍼링된 프리페치를 사용하여 I/O를 차단하지 않고 디스크에서 데이터를 생성할 수 있도록 하겠습니다. 데이터를 로드할 때 다음 두 가지 중요한 메서드를 사용해야 합니다.\n",
        "\n",
        ".cache()는 첫 번째 epoch 동안 디스크에서 이미지를 로드한 후 이미지를 메모리에 유지합니다. 이렇게 하면 모델을 훈련하는 동안 데이터세트가 병목 상태가 되지 않습니다. 데이터세트가 너무 커서 메모리에 맞지 않는 경우, 이 메서드를 사용하여 성능이 높은 온디스크 캐시를 생성할 수도 있습니다.\n",
        "\n",
        ".prefetch()는 훈련 중에 데이터 전처리 및 모델 실행과 겹칩니다."
      ],
      "metadata": {
        "id": "-hlbukbKA9X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "taf1yzvNA24c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 훈련하기\n",
        "완전성을 위해 준비한 데이터세트를 사용하여 간단한 모델을 훈련하는 방법을 보여줍니다. 이 모델은 어떤 식으로든 조정되지 않았습니다. 목표는 방금 만든 데이터세트를 사용하여 역학을 보여주는 것입니다. "
      ],
      "metadata": {
        "id": "Uh015YhlBHFM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 만들기\n",
        "\n",
        "[순차](https://www.tensorflow.org/guide/keras/sequential_model) 모델은 각각에 최대 풀링 레이어(`tf.keras.layers.MaxPooling2D`)가 있는 3개의 컨볼루션 블록(`tf.keras.layers.Conv2D`)으로 구성됩니다. ReLU 활성화 함수(`'relu'`)에 의해 활성화되는 128개 유닛이 있는 완전 연결된 레이어(`tf.keras.layers.Dense`)가 있습니다. 이 모델은 높은 정확도를 위해 조정되지 않았습니다. 이 튜토리얼의 목표는 표준 접근 방식을 보여주는 것입니다."
      ],
      "metadata": {
        "id": "73t6JGikCkbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "v8YVBvzLBYSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 컴파일하기\n",
        "\n",
        "이 튜토리얼에서는 `tf.keras.optimizers.Adam` 옵티마이저와 `tf.keras.losses.SparseCategoricalCrossentropy` 손실 함수를 선택합니다. 각 훈련 epoch에 대한 훈련 및 검증 정확도를 보려면 `metrics` 인수를 `Model.compile`에 전달합니다."
      ],
      "metadata": {
        "id": "hoeVEYibCzc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='min', verbose=1, patience=5)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "5vyBWrwr8MnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2uso7TWjBhET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 요약\n",
        "\n",
        "모델의 `Model.summary` 메서드를 사용하여 네트워크의 모든 레이어를 봅니다."
      ],
      "metadata": {
        "id": "zV0pj2jaDJBm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llLYH-BXL7Xe"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 훈련하기"
      ],
      "metadata": {
        "id": "83_RyhZfFWDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs,\n",
        "  callbacks=[es, mc]\n",
        ")"
      ],
      "metadata": {
        "id": "U5SZgognFWbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "loaded_model = load_model('best_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(val_ds)[1]))"
      ],
      "metadata": {
        "id": "IjwXpzFA7iyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련 결과 시각화하기"
      ],
      "metadata": {
        "id": "gDX9MDhDFljH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 및 검증 세트에 대한 손실 및 정확도 플롯을 생성합니다."
      ],
      "metadata": {
        "id": "F-6akdjgFmRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "#epochs_range = range(epochs)\n",
        "epochs_range = (0,len(acc))\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sTP0xj4bFoGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "플롯은 훈련 정확도와 검증 정확도가 큰 차이로 떨어져 있으며 모델은 검증 세트에서 약 80%의 정확도만을 달성했음을 보여줍니다.\n",
        "\n",
        "무엇이 잘못되었는지 살펴보고 모델의 전반적인 성능을 향상시키도록 하겠습니다."
      ],
      "metadata": {
        "id": "qNQZ-WXvFyEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history)"
      ],
      "metadata": {
        "id": "lF8L1cbF_6ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in val_ds.take(2):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "    predictions = model.predict(tf.expand_dims(images[i], 0))\n",
        "    score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "    plt.title(\"{} ({:2.0f}% {})\".format(class_names[labels[i]],\n",
        "                                100*np.max(score),\n",
        "                                class_names[np.argmax(score)]))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "pxWkKVbHNw-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 새로운 데이터로 예측하기"
      ],
      "metadata": {
        "id": "nDtCG9TQG2la"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "마지막으로, 모델을 사용하여 훈련 또는 검증 세트에 포함되지 않은 이미지를 분류해 보겠습니다."
      ],
      "metadata": {
        "id": "NjlWkLrBG7Cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flower_url = 'https://www.sciencetimes.co.kr/wp-content/uploads/2020/05/sunflower-3512654_1280.jpg'\n",
        "flower_path = tf.keras.utils.get_file('flower.jpg', origin=flower_url)\n",
        "print(flower_path)\n",
        "#flower_path = \"/content/images/sunflower/496_b0dede7e.jpg\""
      ],
      "metadata": {
        "id": "aY1DoJwhG-nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PIL.Image.open(flower_path)"
      ],
      "metadata": {
        "id": "yeOryvPbG5e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = tf.keras.utils.load_img(\n",
        "    flower_path, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "print(img_array.shape)\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "print(predictions)\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "metadata": {
        "id": "0hh8FzUaHAHk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}